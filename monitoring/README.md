# Using Prometheus Metrics

## Configure existing Prometheus instance to scrape stats generated by Istio

I use a private Kubernetes cluster (__microk8s__) running on a local server. 
__microk8s__' Prometheus addon is an implementation of [Prometheus Operator](https://prometheus.io/docs/).

Verify that Prometheus is deployed and running:
```shell
$ kubectl get pod -n monitoring -l app=prometheus
NAME               READY   STATUS    RESTARTS         AGE
prometheus-k8s-0   2/2     Running   23 (2m40s ago)   14d
```

Please look at 
[PodMonitor](https://github.com/prometheus-operator/prometheus-operator/blob/main/Documentation/api.md#podmonitor) and
[ServiceMonitor](https://github.com/prometheus-operator/prometheus-operator/blob/main/Documentation/api.md#servicemonitor) documentation.

Both the `PodMonitor` and `ServiceMonitor` resources describe the set of targets to be monitored by the
existing Prometheus instance.

The following resource configuration defines 3 resources, which are a `ServiceMonitor`
for `istiod` and `istio-ingressgateway`, and a `PodMonitor` to scrape metrics for
the injected sidecar proxies in the application pods.

```yaml
apiVersion: monitoring.coreos.com/v1
kind: PodMonitor
metadata:
  name: istio-sidecars
spec:
  selector:
    matchLabels:
      security.istio.io/tlsMode: 'istio'
  namespaceSelector:
    matchNames:
      - online-boutique
  podMetricsEndpoints:
    - port: http-envoy-prom
      path: /stats/prometheus
---
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: istio-ingressgateway
spec:
  selector:
    matchLabels:
      istio: ingressgateway
  namespaceSelector:
    matchNames:
      - istio-system
  endpoints:
    - targetPort: http-envoy-prom
      path: /stats/prometheus
---
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: istiod
spec:
  selector:
    matchLabels:
      istio: pilot
  namespaceSelector:
    matchNames:
      - istio-system
  endpoints:
    - port: http-monitoring
      interval: 15s
```

Apply the above resources to __microk8s__ prometheus namespace.
```shell
kubectl apply -n monitoring -f istio-service-and-pod-monitors.yaml
```

## Prometheus UI and Grafana

Make sure to `port-forward` to both Prometheus and Grafana services in the cluster.

Start port-forward for access to Prometheus instance for querying and also the UI :
```shell
kubectl -n monitoring port-forward $(kubectl -n monitoring get po -l app=prometheus --no-headers -o jsonpath='{.items[0].metadata.name}') 9090:9090
```

Start port-forward for access to Grafana:
```shell
kubectl port-forward -n monitoring service/grafana --address 0.0.0.0 3000:3000
```

## Generate Istio metrics

Hit the website a few times at http://$INGRESS to create some metric events.
```shell
for i in {1..20}; do curl -sS http://$INGRESS >> /dev/null; done
```

Then run the following query to access the `istio_requests_total` metric -- this is a COUNTER incremented for every request handled by an Istio proxy.
```shell
curl -sS --data-urlencode query="sum by (destination_app, destination_service, response_code, reporter) (increase(istio_requests_total{source_app=\"istio-ingressgateway\", destination_app!=\"unknown\", reporter=\"source\"}[5m]))" "http://localhost:9090/api/v1/query" | jq .
```
```json
{
  "status": "success",
  "data": {
    "resultType": "vector",
    "result": [
      {
        "metric": {
          "destination_app": "frontend",
          "destination_service": "frontend.online-boutique.svc.cluster.local",
          "reporter": "source",
          "response_code": "200"
        },
        "value": [
          1657835848.619,
          "22.63825"
        ]
      }
    ]
  }
}
```

### Bonus section

The following query access the `istio_requests_total` metrics reported from the server-side Envoy proxy
frontend service, for valid requests from the ingress gateway.
```shell
curl -sS --data-urlencode query="sum by (destination_app, destination_service, response_code, reporter) (increase(istio_requests_total{source_app=\"istio-ingressgateway\", destination_app=\"frontend\", reporter=\"destination\"}[5m]))" "http://localhost:9090/api/v1/query"
```
```json
{
  "status": "success",
  "data": {
    "resultType": "vector",
    "result": [
      {
        "metric": {
          "destination_app": "frontend",
          "destination_service": "frontend-external.online-boutique.svc.cluster.local",
          "reporter": "destination",
          "response_code": "200"
        },
        "value": [
          1657747784.034,
          "22.22222222222222"
        ]
      }
    ]
  }
}
```

Next, send unauthorised traffic to the cart endpoint, and then verify that there is no increase in the `istio_requests_total`
metric for 403 response codes, reported by the frontend service as source.
```shell
for i in {1..20}; do curl -sS http://$INGRESS/cart >> /dev/null; done
```

```shell
curl -sS --data-urlencode query="sum by (destination_app, destination_service, response_code, reporter) (increase(istio_requests_total{source_app=\"istio-ingressgateway\", destination_service=\"frontend\", reporter=\"destination\"}[5m]))" "http://localhost:9090/api/v1/query"
```
```json
{
  "status": "success",
  "data": {
    "resultType": "vector",
    "result": [
      {
        "metric": {
          "destination_app": "frontend",
          "destination_service": "frontend-external.online-boutique.svc.cluster.local",
          "reporter": "destination",
          "response_code": "200"
        },
        "value": [
          1657748791.541,
          "0"
        ]
      },
      {
        "metric": {
          "destination_app": "frontend",
          "destination_service": "frontend-external.online-boutique.svc.cluster.local",
          "reporter": "destination",
          "response_code": "404"
        },
        "value": [
          1657748791.541,
          "0"
        ]
      }
    ]
  }
}
```
